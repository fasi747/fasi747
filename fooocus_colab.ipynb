{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "bbc71b96-9b86-427c-afc4-18a967bbf29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,513 kB of archives.\n",
            "After this operation, 5,441 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "/content\n",
            "Cloning into 'forge'...\n",
            "remote: Enumerating objects: 41984, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 41984 (delta 0), reused 0 (delta 0), pack-reused 41982 (from 2)\u001b[K\n",
            "Receiving objects: 100% (41984/41984), 46.36 MiB | 25.21 MiB/s, done.\n",
            "Resolving deltas: 100% (29153/29153), done.\n",
            "/content/forge\n",
            "/content/forge/models/Stable-diffusion\n",
            "\n",
            "08/27 04:49:37 [\u001b[1;31mERROR\u001b[0m] CUID#7 - Download aborted. URI=https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors\n",
            "Exception: [AbstractCommand.cc:351] errorCode=24 URI=https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors\n",
            "  -> [HttpSkipResponseCommand.cc:215] errorCode=24 Authorization failed.\n",
            "\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "e54cc0|\u001b[1;31mERR\u001b[0m |       0B/s|/content/forge/models/Stable-diffusion/flux1-schnell.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(ERR):error occurred.\n",
            "\n",
            "aria2 will resume download if the transfer is restarted.\n",
            "If there are any errors, then see the log file. See '-l' option in help/man page for details.\n",
            "/content/forge\n",
            "=============================================================================================\n",
            "INCOMPATIBLE PYTHON VERSION\n",
            "\n",
            "This program is tested with 3.10.6 Python, but you have 3.12.11.\n",
            "If you encounter an error with \"RuntimeError: Couldn't install torch.\" message,\n",
            "or any other error regarding unsuccessful package (library) installation,\n",
            "please downgrade (or upgrade) to the latest version of 3.10 Python\n",
            "and delete current Python and \"venv\" folder in WebUI's directory.\n",
            "\n",
            "You can download 3.10 Python from here: https://www.python.org/downloads/release/python-3106/\n",
            "\n",
            "\n",
            "\n",
            "Use --skip-python-version-check to suppress this warning.\n",
            "=============================================================================================\n",
            "Python 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-669-gdfdcbab6\n",
            "Commit hash: dfdcbab685e57677014f05a3309b48cc87383167\n",
            "Installing clip\n",
            "Installing open_clip\n",
            "Installing xformers\n",
            "Cloning assets into /content/forge/repositories/stable-diffusion-webui-assets...\n",
            "Cloning into '/content/forge/repositories/stable-diffusion-webui-assets'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 132.70 KiB | 767.00 KiB/s, done.\n",
            "Cloning huggingface_guess into /content/forge/repositories/huggingface_guess...\n",
            "Cloning into '/content/forge/repositories/huggingface_guess'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 51 (delta 29), reused 32 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (51/51), 37.50 KiB | 650.00 KiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "Cloning BLIP into /content/forge/repositories/BLIP...\n",
            "Cloning into '/content/forge/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.04 MiB | 12.40 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Installing requirements\n",
            "Installing forge_legacy_preprocessor requirement: fvcore\n",
            "Installing forge_legacy_preprocessor requirement: mediapipe\n",
            "Installing forge_legacy_preprocessor requirement: onnxruntime\n",
            "Installing forge_legacy_preprocessor requirement: svglib\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "Installing forge_legacy_preprocessor requirement: handrefinerportable\n",
            "Installing forge_legacy_preprocessor requirement: depth_anything\n",
            "Installing forge_legacy_preprocessor requirement: depth_anything_v2\n",
            "Launching Web UI with arguments: --share --xformers\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "pytorch version: 2.8.0+cu126\n",
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.3.1+cu121 with CUDA 1201 (you have 2.8.0+cu126)\n",
            "    Python  3.12.4 (you have 3.12.11)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "/usr/local/lib/python3.12/dist-packages/xformers/ops/swiglu_op.py:127: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/xformers/ops/swiglu_op.py:148: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n",
            "xformers version: 0.0.27\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype preferences: [torch.float32] -> torch.float32\n",
            "Installing bitsandbytes==0.45.3\n",
            "CUDA Using Stream: False\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2025-08-27 05:01:24.023053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756270884.055373    1177 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756270884.064412    1177 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1756270884.079804    1177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756270884.079838    1177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756270884.079842    1177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1756270884.079846    1177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-27 05:01:24.084316: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "/content/forge/modules/prompt_parser.py:393: SyntaxWarning: invalid escape sequence '\\('\n",
            "  \\( - literal character '('\n",
            "/content/forge/modules/infotext_utils.py:21: SyntaxWarning: invalid escape sequence '\\('\n",
            "  re_hypernet_hash = re.compile(\"\\(([0-9a-f]+)\\)$\")\n",
            "/content/forge/modules/models/diffusion/uni_pc/uni_pc.py:52: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  The `alphas_cumprod` is the \\hat{alpha_n} arrays in the notations of DDPM. Specifically, DDPMs assume that\n",
            "ControlNet preprocessor location: /content/forge/models/ControlNetPreprocessor\n",
            "2025-08-27 05:01:36,312 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "You do not have any model!\n",
            "Model selected: {'checkpoint_info': None, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://b376ec6b3b5f06a8c3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 722.0s (prepare environment: 689.6s, launcher: 0.5s, import torch: 24.4s, other imports: 0.6s, load scripts: 2.2s, create ui: 2.8s, gradio launch: 1.6s).\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14071.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# Install Forge (WebUI) with Flux\n",
        "# ================================\n",
        "\n",
        "# 1. Update Colab and install dependencies\n",
        "!apt -y update -qq\n",
        "!apt -y install -qq aria2 git-lfs\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 2. Clone Forge repo\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/stable-diffusion-webui-forge forge\n",
        "%cd forge\n",
        "\n",
        "# 3. Get Flux model weights (example: Flux.1 Schnell)\n",
        "!mkdir -p /content/forge/models/Stable-diffusion\n",
        "%cd /content/forge/models/Stable-diffusion\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \\\n",
        "  https://huggingface.co/black-forest-labs/FLUX.1-schnell/resolve/main/flux1-schnell.safetensors \\\n",
        "  -o flux1-schnell.safetensors\n",
        "\n",
        "# 4. Launch Forge WebUI\n",
        "%cd /content/forge\n",
        "!python launch.py --share --xformers\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}